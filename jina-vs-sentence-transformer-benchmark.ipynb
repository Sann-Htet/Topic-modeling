{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T06:52:28.069548Z","iopub.status.busy":"2024-05-07T06:52:28.068744Z","iopub.status.idle":"2024-05-07T06:52:28.074651Z","shell.execute_reply":"2024-05-07T06:52:28.073624Z","shell.execute_reply.started":"2024-05-07T06:52:28.069505Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:57.662070Z","iopub.status.busy":"2024-05-07T08:49:57.661325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecc62e0009be4ac5b0e2fe533f79eb82","version_major":2,"version_minor":0},"text/plain":["configuration_bert.py:   0%|          | 0.00/8.24k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n","- configuration_bert.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c0d8fd19e7b43cfb9b92a0ca3797cc6","version_major":2,"version_minor":0},"text/plain":["modeling_bert.py:   0%|          | 0.00/97.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n","- modeling_bert.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 30.47 GiB. GPU ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m doc_embedder \u001b[38;5;241m=\u001b[39m SentenceTransformersDocumentEmbedder(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinaai/jina-embeddings-v2-base-en\u001b[39m\u001b[38;5;124m\"\u001b[39m,trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m doc_embedder\u001b[38;5;241m.\u001b[39mwarm_up()\n\u001b[0;32m---> 28\u001b[0m docs_with_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mdoc_embedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m document_store\u001b[38;5;241m.\u001b[39mwrite_documents(docs_with_embeddings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     31\u001b[0m retriever \u001b[38;5;241m=\u001b[39m InMemoryEmbeddingRetriever(document_store, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/haystack/components/embedders/sentence_transformers_document_embedder.py:174\u001b[0m, in \u001b[0;36mSentenceTransformersDocumentEmbedder.run\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    169\u001b[0m     text_to_embed \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_separator\u001b[38;5;241m.\u001b[39mjoin(meta_values_to_embed \u001b[38;5;241m+\u001b[39m [doc\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffix\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    172\u001b[0m     texts_to_embed\u001b[38;5;241m.\u001b[39mappend(text_to_embed)\n\u001b[0;32m--> 174\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(documents, embeddings):\n\u001b[1;32m    182\u001b[0m     doc\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m emb\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:53\u001b[0m, in \u001b[0;36m_SentenceTransformersEmbeddingBackend.embed\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m---> 53\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:371\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    368\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 371\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m truncate_embeddings(\n\u001b[1;32m    373\u001b[0m         out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/f3ec4cf7de7e561007f27c9efc7148b0bd713f81/modeling_bert.py:1419\u001b[0m, in \u001b[0;36mJinaBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1410\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1412\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1413\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1414\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1418\u001b[0m )\n\u001b[0;32m-> 1419\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1432\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1434\u001b[0m )\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/f3ec4cf7de7e561007f27c9efc7148b0bd713f81/modeling_bert.py:824\u001b[0m, in \u001b[0;36mJinaBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    814\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    815\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    816\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m         alibi_bias,\n\u001b[1;32m    822\u001b[0m     )\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/f3ec4cf7de7e561007f27c9efc7148b0bd713f81/modeling_bert.py:621\u001b[0m, in \u001b[0;36mJinaBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, bias, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    608\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    619\u001b[0m         past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     )\n\u001b[0;32m--> 621\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/f3ec4cf7de7e561007f27c9efc7148b0bd713f81/modeling_bert.py:501\u001b[0m, in \u001b[0;36mJinaBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, bias)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    492\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m     bias: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 501\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    512\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    514\u001b[0m     ]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina-bert-implementation/f3ec4cf7de7e561007f27c9efc7148b0bd713f81/modeling_bert.py:366\u001b[0m, in \u001b[0;36mJinaBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, bias)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (attn\u001b[38;5;241m.\u001b[39mview(b, s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size),)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_key\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_key_query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m ):\n\u001b[1;32m    372\u001b[0m     query_length, key_length \u001b[38;5;241m=\u001b[39m query_layer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], key_layer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 30.47 GiB. GPU "]}],"source":["\n","from haystack import Document\n","from haystack.components.converters import TextFileToDocument\n","from haystack.components.embedders import (\n","    SentenceTransformersDocumentEmbedder,\n","    SentenceTransformersTextEmbedder,\n",")\n","from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n","from haystack.components.retrievers.in_memory.embedding_retriever import (\n","    InMemoryEmbeddingRetriever,\n",")\n","from haystack.components.writers import DocumentWriter\n","from haystack.document_stores.in_memory import InMemoryDocumentStore\n","\n","doc_dir = \"./game-of-thrones\"\n","document_store = InMemoryDocumentStore()\n","text_file_converter = TextFileToDocument()\n","cleaner = DocumentCleaner()\n","splitter = DocumentSplitter(split_length = 600, split_overlap=40)\n","writer = DocumentWriter(document_store)\n","\n","dataset = load_dataset(\"Tuana/game-of-thrones\",split=\"train\")\n","\n","\n","# doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L12-v2\", progress_bar=False)\n","# doc_embedder = SentenceTransformersDocumentEmbedder(model=\"jinaai/jina-embedding-l-en-v1\", progress_bar=False)\n","doc_embedder = SentenceTransformersDocumentEmbedder(model=\"jinaai/jina-embeddings-v2-base-en\",trust_remote_code=True, progress_bar=False)\n","doc_embedder.warm_up()\n","docs_with_embeddings = doc_embedder.run([Document(**ds) for ds in dataset])\n","document_store.write_documents(docs_with_embeddings[\"documents\"])\n","\n","retriever = InMemoryEmbeddingRetriever(document_store, top_k=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# query = \"\"\"\n","# Arya runs away from King's Landing with Yoren and his group. She becomes friends with Lommy, Gendry, and Hot Pie.\n","# They are attacked by Amory Lorch, but Arya and the others escape through a tunnel.\n","# Arya frees three prisoners, including Jaqen H'ghar.\n","# \"\"\"\n","# query = \"\"\"\n","# Arya, Gendry, and Hot Pie encounter Thoros of Myr, a Red Priest who is a member of the Brotherhood Without Banners, a group of men sent by Ned to restore order in the Riverlands. As Thoros takes them to the Brotherhood's hideout they encounter the Hound, a captive of other Brotherhood men. The Hound is brought before the Brotherhood's leader, Ser Beric Dondarrion, and after Arya accuses him of Mycah's murder Beric sentences him to trial by combat. The Hound wins, to Arya's fury, and is released by Dondarrion. Arya is further enraged when the Brotherhood sells Gendry to Melisandre and escapes the Brotherhood. She is captured by the Hound, who intends to take her to The Twins to ransom her to her brother Robb. However, as they arrive the Freys betray the Starks and slaughter their forces, with Arya barely escaping the massacre. In the aftermath of their escape, Arya encounters a Frey soldier bragging about his role in desecrating Robb's corpse. Arya stabs the soldier to death, marking the first time she has deliberately killed another person. ====Season 4====\n","# \"\"\"\n","query = \"\"\"\n","The Night King is shown leading his army south. Through ravens' eyes, Bran locates the Night King's army beyond the Wall.\n","\"\"\"\n","# query = \"\"\"\n","# Arya escapes King's Landing with Yoren and his party of recruits; and on the road, she clashes with the other Night's Watch child recruits Lommy, Gendry, and Hot Pie but eventually befriends them. On the way, the party is attacked by Amory Lorch when Yoren refuses to yield Gendry, who is actually a bastard son of the late King Robert, to the Lannisters.  The Night's Watch convoy is overrun and massacred, but Arya and the other children escape through a tunnel.  Before escaping, she rescues three prisoners locked in a wagon cage, among them a mysterious man named Jaqen H'ghar.\n","# \"\"\"\n","text_embedder = SentenceTransformersTextEmbedder(model=\"jinaai/jina-embedding-l-en-v1\", progress_bar=False)\n","text_embedder.warm_up()\n","query_embedding = text_embedder.run(query)[\"embedding\"]\n","\n","result = retriever.run(query_embedding=query_embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","===In the Riverlands===\n","Sandor and Arya continue their journey to the Vale.\n"]}],"source":["print(result[\"documents\"][0].content)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/nozander/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.nn.functional import cosine_similarity\n","import torch\n","\n","def extract_similar_answer_sentences(\n","    query_content: str,\n","    doc_content: str,\n","    doc_embedder,\n","    threshold: float = 0.9,\n","    ) -> str:\n","    query_lines = nltk.sent_tokenize(query_content)\n","    answer_lines = nltk.sent_tokenize(doc_content)\n","\n","    answer_embed = torch.tensor([text_embedder.run(line)[\"embedding\"] for line in query_lines])\n","    query_embed = torch.tensor([text_embedder.run(line)[\"embedding\"] for line in answer_lines])\n","\n","    similarity_matrix = cosine_similarity(query_embed.unsqueeze(0), answer_embed.unsqueeze(1), dim=2)\n","\n","    _, answer_indices = torch.nonzero(similarity_matrix > threshold, as_tuple=True)\n","\n","    if len(answer_indices) == 0:\n","        _, max_indices = torch.max(similarity_matrix, dim=1)\n","        best_answer_combined = \"\\n\".join([answer_lines[i] for i in torch.unique(max_indices)])\n","    else:\n","        best_answer_combined = \"\\n\".join([answer_lines[i] for i in torch.unique(answer_indices)])\n","\n","    return best_answer_combined"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:32.801443Z","iopub.status.busy":"2024-05-07T08:49:32.800526Z","iopub.status.idle":"2024-05-07T08:49:32.806940Z","shell.execute_reply":"2024-05-07T08:49:32.805848Z","shell.execute_reply.started":"2024-05-07T08:49:32.801410Z"},"trusted":true},"outputs":[],"source":["def search(query):\n","  query_embedding = text_embedder.run(query)[\"embedding\"]\n","\n","  result = retriever.run(query_embedding=query_embedding)\n","  answer_content = result[\"documents\"][0].content\n","  similarity_answer = extract_similar_answer_sentences(query, answer_content, text_embedder)\n","\n","  return similarity_answer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:33.080469Z","iopub.status.busy":"2024-05-07T08:49:33.079559Z","iopub.status.idle":"2024-05-07T08:49:33.874848Z","shell.execute_reply":"2024-05-07T08:49:33.873829Z","shell.execute_reply.started":"2024-05-07T08:49:33.080436Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\n===In the Riverlands===\\nSandor and Arya continue their journey to the Vale.'"]},"execution_count":105,"metadata":{},"output_type":"execute_result"}],"source":["search(query)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:33.907089Z","iopub.status.busy":"2024-05-07T08:49:33.906296Z","iopub.status.idle":"2024-05-07T08:49:33.912304Z","shell.execute_reply":"2024-05-07T08:49:33.911326Z","shell.execute_reply.started":"2024-05-07T08:49:33.907058Z"},"trusted":true},"outputs":[],"source":["sentences = [\n","    \"Tyrion is introduced as the third and youngest child of wealthy and powerful Tywin Lannister, the former Hand of the King, and Joanna Lannister\",\n","    \"The Valyrians are characterized by their silver hair and violet eyes. Valyria was called The Freehold because every man who owned land was allowed to vote for their leaders.\",\n","    \"Arya, Gendry, and Hot Pie encounter Thoros of Myr, a Red Priest who is a member of the Brotherhood Without Banners, a group of men sent by Ned to restore order in the Riverlands.\",\n","    \"In the fifth season, the region of Dorne is introduced as a location. Alexander Siddig joins the cast as Doran Martell, the ruling Prince of Dorne, and elder brother of Oberyn Martell, while his son Trystane Martell is portrayed by Toby Sebastian.\",\n","    \"the Red Keep's gardens (identified as a godswood in the novels) the production used the cloister of the St Dominic Monastery in Rabat, in Malta.\",\n","    \"The novels were later on adapted to the hit HBO series ''Game of Thrones'' in 2011.\",\n","    \"Arya Stark's training with the Faceless Men in Braavos tests her identity and purpose in ways she never imagined.\",\n","    \"It first played during the season six finale of the show and was composed by Ramin Djawadi in 2016\",\n","    \"Naath, also known as the Isle of Butterflies, is an island off the north-west coast of Sothoryos that lies west of the Basilisk Isles.\",\n","    \"Arya runs away from King's Landing with Yoren and his group. She becomes friends with Lommy, Gendry, and Hot Pie. They are attacked by Amory Lorch, but Arya and the others escape through a tunnel. Arya frees three prisoners, including Jaqen H'ghar.\"\n","    ]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:34.366016Z","iopub.status.busy":"2024-05-07T08:49:34.365673Z","iopub.status.idle":"2024-05-07T08:49:37.765395Z","shell.execute_reply":"2024-05-07T08:49:37.764300Z","shell.execute_reply.started":"2024-05-07T08:49:34.365990Z"},"trusted":true},"outputs":[],"source":["answers = []\n","for sentence in sentences:\n","  answers.append(search(sentence))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:37.767703Z","iopub.status.busy":"2024-05-07T08:49:37.767327Z","iopub.status.idle":"2024-05-07T08:49:39.001071Z","shell.execute_reply":"2024-05-07T08:49:39.000047Z","shell.execute_reply.started":"2024-05-07T08:49:37.767670Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:39.002844Z","iopub.status.busy":"2024-05-07T08:49:39.002537Z","iopub.status.idle":"2024-05-07T08:49:39.009331Z","shell.execute_reply":"2024-05-07T08:49:39.008393Z","shell.execute_reply.started":"2024-05-07T08:49:39.002818Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer\n","\n","def calculate_similarity(query, answer):\n","\n","    model = SentenceTransformer('bert-base-nli-mean-tokens')\n","    embed_query = model.encode([query], show_progress_bar=False)\n","    embed_answer = model.encode([answer], show_progress_bar=False)\n","\n","    similarity_matrix = cosine_similarity(embed_query, embed_answer)\n","\n","    similarity_score = similarity_matrix[0][0]\n","\n","    return similarity_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["['\\n==Storylines==\\nCoat of arms of House Lannister',\n"," '\\n===In the Riverlands===\\nSandor and Arya continue their journey to the Vale.',\n"," '\\n===In the Riverlands===\\nSandor and Arya continue their journey to the Vale.',\n"," '\\n====In the Riverlands====\\n* Gary Oliver as Ternesio Terys',\n"," '\\n===Filming===\\nThe Minčeta Tower in Dubrovnik was used as the location of the House of the Undying.',\n"," '\\n== Storylines ==\\nCoat of arms of House Lannister',\n"," '\\n===In the Riverlands===\\nSandor and Arya continue their journey to the Vale.',\n"," '\\n===Music===\\nRamin Djawadi returned as the composer of the show for the seventh season.',\n"," '\\n====Naath====\\nNaath, also known as the Isle of Butterflies, is an island off the north-west coast of Sothoryos that lies west of the Basilisk Isles.',\n"," '\\n===In the Riverlands===\\nSandor and Arya continue their journey to the Vale.']"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["answers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:39.011826Z","iopub.status.busy":"2024-05-07T08:49:39.011479Z","iopub.status.idle":"2024-05-07T08:49:39.343925Z","shell.execute_reply":"2024-05-07T08:49:39.342849Z","shell.execute_reply.started":"2024-05-07T08:49:39.011801Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Mean Score: 0.51\n"]}],"source":["# Mean score for \"jinaai/jina-embeddings-v2-base-en\"\n","scores = []\n","for sentence, answer in zip(sentences, answers):\n","  scores.append(calculate_similarity(sentence, answer))\n","print(f\"Mean Score: {sum(scores) / len(scores):.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:39.345831Z","iopub.status.busy":"2024-05-07T08:49:39.345390Z","iopub.status.idle":"2024-05-07T08:49:39.673928Z","shell.execute_reply":"2024-05-07T08:49:39.672825Z","shell.execute_reply.started":"2024-05-07T08:49:39.345791Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/run/media/nozander/c8a3e945-09e9-4905-9f64-2b593e6a1297/FOIA-Kit/foiakit-datascience/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Mean Score: 0.51\n"]}],"source":["# Mean score for \"sentence-transformers/all-MiniLM-L12-v2\"\n","scores = []\n","for sentence, answer in zip(sentences, answers):\n","  scores.append(calculate_similarity(sentence, answer))\n","print(f\"Mean Score: {sum(scores) / len(scores):.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:49:44.071880Z","iopub.status.busy":"2024-05-07T08:49:44.071486Z","iopub.status.idle":"2024-05-07T08:49:44.078218Z","shell.execute_reply":"2024-05-07T08:49:44.077229Z","shell.execute_reply.started":"2024-05-07T08:49:44.071840Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\n====In the Riverlands====\\n* Gary Oliver as Ternesio Terys'"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["# sample semantic search answer using \"jinaai/jina-embeddings-v2-base-en\"\n","query = \"\"\"\n","Ramsay draws the ire of Roose after flaying the family of a Northern lord who refuses to pledge fealty.\n","\"\"\"\n","answers[3]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:43:49.437391Z","iopub.status.busy":"2024-05-07T08:43:49.436526Z","iopub.status.idle":"2024-05-07T08:43:49.443092Z","shell.execute_reply":"2024-05-07T08:43:49.442070Z","shell.execute_reply.started":"2024-05-07T08:43:49.437358Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\n====In the Riverlands====\\n* Gary Oliver as Ternesio Terys'"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["# sample semantic search answer using \"sentence-transformers/all-MiniLM-L12-v2\"\n","query = \"\"\"\n","Ramsay draws the ire of Roose after flaying the family of a Northern lord who refuses to pledge fealty.\n","\"\"\"\n","answers[3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:43:44.362654Z","iopub.status.busy":"2024-05-07T08:43:44.361441Z","iopub.status.idle":"2024-05-07T08:43:44.368834Z","shell.execute_reply":"2024-05-07T08:43:44.367876Z","shell.execute_reply.started":"2024-05-07T08:43:44.362591Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\n====In the Riverlands====\\n* Gary Oliver as Ternesio Terys'"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["answers[3]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:31:02.970524Z","iopub.status.busy":"2024-05-07T08:31:02.969797Z","iopub.status.idle":"2024-05-07T08:31:03.033513Z","shell.execute_reply":"2024-05-07T08:31:03.032140Z","shell.execute_reply.started":"2024-05-07T08:31:02.970491Z"},"trusted":true},"outputs":[],"source":["query = \"\"\"\n","Ramsay draws the ire of Roose after flaying the family of a Northern lord who refuses to pledge fealty.\n","\"\"\"\n","# text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L12-v2\", progress_bar=False)\n","text_embedder = SentenceTransformersTextEmbedder(model=\"jinaai/jina-embedding-l-en-v1\", progress_bar=False)\n","text_embedder.warm_up()\n","query_embedding = text_embedder.run(query)[\"embedding\"]\n","\n","result = retriever.run(query_embedding=query_embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T08:31:17.641562Z","iopub.status.busy":"2024-05-07T08:31:17.641206Z","iopub.status.idle":"2024-05-07T08:31:17.647630Z","shell.execute_reply":"2024-05-07T08:31:17.646667Z","shell.execute_reply.started":"2024-05-07T08:31:17.641533Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\n===In the Riverlands===\\nSandor and Arya continue their journey to the Vale.'"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["result['documents'][0].content"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'content', 'content_type', 'meta', 'score', 'embedding'],\n","    num_rows: 2357\n","})"]},"execution_count":117,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4935861,"sourceId":8309350,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
